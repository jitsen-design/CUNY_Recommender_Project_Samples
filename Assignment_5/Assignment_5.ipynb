{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5 - Spark \n",
    "\n",
    "For this exercise, we'll use Spark on an AWS EC2 machine. \n",
    "\n",
    "### AWS Machine Specs \n",
    "The machine is a T2 Extra Large machine with fore cores and 16GB of RAM.\n",
    "\n",
    "### Spark Setup\n",
    "We'll use PySpark with two partitions. We are running four cores, and Spark with use these to run parallel jobs\n",
    "\n",
    "### Objective\n",
    "The objective of this exercise is to compare an Apache Spark distributed setup with my local computer and compare efficiency. We'll compare the PySpark model against our trusty Surprise Package. Let's once again use the [Beer Recommender](https://github.com/pburkard88/DS_BOS_06/tree/master/Data) data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules and Libraries for Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests, os, sys, zipfile, io\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import pyspark\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import json\n",
    "import surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Secrets File to Get Path to Spark Master \n",
    "\n",
    "(I don't want my internal IP in the public domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/secrets.json') as f:\n",
    "    pyspark_config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark Session with Link to Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.master(pyspark_config['master']).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Default Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.defaultMinPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Default Parallelism (since we have four cores)\n",
    "\n",
    "We can see that spark has automatically detected that we can run four parallel operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.defaultParallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data and Import into Spark RDD format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "ratings = spark.read.csv('data/beer_reviews.csv',\n",
    "                        sep=',',\n",
    "                        inferSchema=True,\n",
    "                        header=True)\n",
    "                         \n",
    "                         \n",
    "\n",
    "for i in ['reviewer_id', \n",
    "         'beer_beerid']:\n",
    "         ratings = ratings.withColumn(i, ratings[i].cast('int'))\n",
    "    \n",
    "ratings = ratings.withColumn(\"review_overall\", ratings[\"review_overall\"].cast('float'))\n",
    "\n",
    "ratings = ratings[['reviewer_id',\n",
    "                   'beer_beerid',\n",
    "                   'review_overall']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Spark ALS instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(userCol='reviewer_id',\n",
    "          itemCol='beer_beerid',\n",
    "          ratingCol='review_overall',\n",
    "          nonnegative=True,\n",
    "          rank=20,\n",
    "          seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = ratings.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the fit time of ALS to compare later with non-distributed computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 11.8 s per loop\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "% timeit als_model = als.fit(dataset=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model took 12s to fit with 20 weights. Let's remember that for later on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the test set\n",
    "als_model = als.fit(train)\n",
    "als_pred = als_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_pred = als_pred.withColumn('diff_sq', (als_pred['review_overall'] - als_pred['prediction'])**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RMSE for the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|              rmse|\n",
      "+------------------+\n",
      "|0.6224995404916362|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as func\n",
    "\n",
    "# the aggregate function can be created outside of the dataframe if desired\n",
    "rms_calc = func.sqrt(func.mean('diff_sq'))\n",
    "\n",
    "als_pred.dropna().select(rms_calc.alias('rmse') ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Best Model with Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ALS instance\n",
    "als = ALS(userCol='reviewer_id',\n",
    "          itemCol='beer_beerid',\n",
    "          ratingCol='review_overall',\n",
    "          nonnegative=True,\n",
    "          seed=42)\n",
    "\n",
    "# The parameter grid to search\n",
    "\n",
    "als_paramgrid = (ParamGridBuilder()\n",
    "                 .addGrid(als.rank, [10, 20])\n",
    "                 .addGrid(als.maxIter, [10])\n",
    "                 .addGrid(als.regParam, [0.1,.5])\n",
    "                 .addGrid(als.alpha, [0.5, 1.0])\n",
    "                 .build())\n",
    "\n",
    "# The evaluation function for determining the best model\n",
    "rmse_eval = RegressionEvaluator(labelCol='review_overall',\n",
    "                                predictionCol='prediction', \n",
    "                                metricName='rmse')\n",
    "\n",
    "# The cross validation instance\n",
    "cv = CrossValidator(estimator=als,\n",
    "                    parallelism=4,\n",
    "                    collectSubModels=True,\n",
    "                    estimatorParamMaps=als_paramgrid,\n",
    "                    evaluator=rmse_eval,\n",
    "                    numFolds=3, \n",
    "                    seed=42)\n",
    "\n",
    "# Fit the models and find the best one!\n",
    "als_cv = cv.fit(train.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best model and Get Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_best = als_cv.bestModel\n",
    "als_best.rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Best Regularization Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als.getRegParam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a Visual Comparison of Predictions on Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "als_pred_best = als_best.transform(test)\n",
    "als_pred_best_df = als_pred_best.dropna().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>beer_beerid</th>\n",
       "      <th>review_overall</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4219</td>\n",
       "      <td>148</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.867328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16916</td>\n",
       "      <td>148</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.472813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20596</td>\n",
       "      <td>148</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.213685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23607</td>\n",
       "      <td>148</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.851794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6482</td>\n",
       "      <td>148</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.817792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewer_id  beer_beerid  review_overall  prediction\n",
       "0         4219          148             4.0    3.867328\n",
       "1        16916          148             3.5    3.472813\n",
       "2        20596          148             4.0    4.213685\n",
       "3        23607          148             4.0    3.851794\n",
       "4         6482          148             3.5    3.817792"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_pred_best_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>beer_beerid</th>\n",
       "      <th>review_overall</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461806</th>\n",
       "      <td>16338</td>\n",
       "      <td>75739</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.270440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461807</th>\n",
       "      <td>28855</td>\n",
       "      <td>75739</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.184555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461808</th>\n",
       "      <td>8430</td>\n",
       "      <td>75739</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.967432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461809</th>\n",
       "      <td>16894</td>\n",
       "      <td>75999</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.278557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461810</th>\n",
       "      <td>12378</td>\n",
       "      <td>76694</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.828838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reviewer_id  beer_beerid  review_overall  prediction\n",
       "461806        16338        75739             4.0    3.270440\n",
       "461807        28855        75739             4.0    3.184555\n",
       "461808         8430        75739             3.0    2.967432\n",
       "461809        16894        75999             4.5    3.278557\n",
       "461810        12378        76694             3.5    2.828838"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_pred_best_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The predictions don't seem too bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get RMSE on Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|              rmse|\n",
      "+------------------+\n",
      "|0.6234894689615749|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "als_pred_best = als_pred_best.withColumn('diff_sq', (als_pred_best['review_overall'] - als_pred_best['prediction'])**2)\n",
    "als_pred_best.dropna().select(rms_calc.alias('rmse') ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best RMSE is almost identical to our default model\n",
    "\n",
    "### Get Recommended for All Beers\n",
    "\n",
    "(This'll require some preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend top five users\n",
    "recommendations_df = als_best.recommendForAllItems(5).toPandas()\n",
    "\n",
    "# Get Ids for users and ingore values\n",
    "recommendations_df['recommendations'] = recommendations_df['recommendations'].apply(lambda x: [y[0] for y in x])\n",
    "\n",
    "# Get column for each user\n",
    "recommendations_df = recommendations_df[['beer_beerid']].join(\n",
    "                     recommendations_df['recommendations'].apply(pd.Series))\n",
    "\n",
    "# turn dataframe into long form\n",
    "recommendations_df = pd.melt(recommendations_df,\n",
    "                             id_vars='beer_beerid',\n",
    "                             var_name='rec_index', \n",
    "                             value_name='Recommended User Ids'\n",
    "                             ).drop(labels=['rec_index'],\n",
    "                                    axis=1)\n",
    "\n",
    "# Get dataframes for mapping ids to names\n",
    "beer_df = pd.read_csv('data/beer_reviews.csv')[['beer_beerid',\n",
    "                                                'beer_name']].drop_duplicates().set_index('beer_beerid')\n",
    "user_df = pd.read_csv('data/beer_reviews.csv')[['reviewer_id',\n",
    "                                                'review_profilename']].drop_duplicates().set_index('reviewer_id')\n",
    "\n",
    "### Get dictionaries mapping Ids to names\n",
    "user_dict={}\n",
    "beer_dict={}\n",
    "for i,j in beer_df.iterrows():\n",
    "    beer_dict[i] = j['beer_name']\n",
    "for i,j in user_df.iterrows():    \n",
    "    user_dict[i] = j['review_profilename']\n",
    "    \n",
    "    \n",
    "# map!\n",
    "recommendations_df['Recommended Users'] = recommendations_df['Recommended User Ids'].map(user_dict)\n",
    "recommendations_df['Beer'] = recommendations_df['beer_beerid'].map(beer_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_beerid</th>\n",
       "      <th>Recommended User Ids</th>\n",
       "      <th>Recommended Users</th>\n",
       "      <th>Beer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>8328</td>\n",
       "      <td>MichiganMike</td>\n",
       "      <td>Brooklyn Lager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>463</td>\n",
       "      <td>17643</td>\n",
       "      <td>crbauman</td>\n",
       "      <td>Oregon Honey Beer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>833</td>\n",
       "      <td>22084</td>\n",
       "      <td>jams7611</td>\n",
       "      <td>Samuel Adams Pale Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1088</td>\n",
       "      <td>22084</td>\n",
       "      <td>jams7611</td>\n",
       "      <td>Old Whiskers Hefeweizen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1238</td>\n",
       "      <td>22084</td>\n",
       "      <td>jams7611</td>\n",
       "      <td>Pale Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1580</td>\n",
       "      <td>22084</td>\n",
       "      <td>jams7611</td>\n",
       "      <td>Eroica Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1591</td>\n",
       "      <td>22084</td>\n",
       "      <td>jams7611</td>\n",
       "      <td>Winter Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1645</td>\n",
       "      <td>29016</td>\n",
       "      <td>rumguzzler</td>\n",
       "      <td>Bruegel Amber Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1959</td>\n",
       "      <td>22084</td>\n",
       "      <td>jams7611</td>\n",
       "      <td>Farmhouse Summer Ale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2122</td>\n",
       "      <td>4590</td>\n",
       "      <td>Feliks</td>\n",
       "      <td>Blue Ridge Subliminator Dopplebock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beer_beerid  Recommended User Ids Recommended Users  \\\n",
       "0          148                  8328      MichiganMike   \n",
       "1          463                 17643          crbauman   \n",
       "2          833                 22084          jams7611   \n",
       "3         1088                 22084          jams7611   \n",
       "4         1238                 22084          jams7611   \n",
       "5         1580                 22084          jams7611   \n",
       "6         1591                 22084          jams7611   \n",
       "7         1645                 29016        rumguzzler   \n",
       "8         1959                 22084          jams7611   \n",
       "9         2122                  4590            Feliks   \n",
       "\n",
       "                                 Beer  \n",
       "0                      Brooklyn Lager  \n",
       "1                   Oregon Honey Beer  \n",
       "2               Samuel Adams Pale Ale  \n",
       "3             Old Whiskers Hefeweizen  \n",
       "4                            Pale Ale  \n",
       "5                          Eroica Ale  \n",
       "6                          Winter Ale  \n",
       "7                   Bruegel Amber Ale  \n",
       "8                Farmhouse Summer Ale  \n",
       "9  Blue Ridge Subliminator Dopplebock  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the dataframe to save memory\n",
    "del recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Spark ALS with Surprise Package\n",
    "\n",
    "Let's comapre Spark's computing efficiency with the Surprise Package's speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Surprise Model's Baseline Model to Fit the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv('data/beer_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn dataframe into model readable by Surprise PAckage\n",
    "reader = surprise.Reader(rating_scale=(0, 5))\n",
    "data_surprise = surprise.Dataset.load_from_df(data[['reviewer_id',\n",
    "                                                    'beer_beerid',\n",
    "                                                    'review_overall']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Test Train split and Run Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "1 loop, best of 3: 3.41 s per loop\n"
     ]
    }
   ],
   "source": [
    "trainset, testset = surprise.model_selection.train_test_split(data_surprise, test_size=.3)\n",
    "\n",
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 10,\n",
    "               'reg_u': 12,\n",
    "               'reg_i': 5\n",
    "               }\n",
    "algo = surprise.BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "% timeit algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### We can see that the baseline model took a very short time to run. This is not surprising (no pun intended), given that we are not doing any factorization. Let's now do the actual factorization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 18.9 s per loop\n"
     ]
    }
   ],
   "source": [
    "algo = surprise.SVD(n_factors=20,\n",
    "                    n_epochs=10)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "% timeit algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### We can see that the Spark distributed computing model (12 seconds) outperforms the Surprise package (19 seocnds) thanks to parallel processing. However, the gains are small, so we may disregard it even for a dataset for this size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "#### We did not use a super massive dataset (1.5 million rows), so the incremental benefit of using Spark was not terribly visible. The biggest benefit came from using the AWS EC2 instance. Perhaps if we had a dataset with 15-20 million rows, distributed computing would have been more beneficial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
